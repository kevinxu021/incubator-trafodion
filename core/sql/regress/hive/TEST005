-- -*- mode: sql; coding: utf-8 -*-
-- Tests for SQL on Hadoop PoC
-- Test simple cases of partitioned tables
-- Very basic test of data types and Unicode
-- Basic test of metadata invalidation
-- Added April 2013
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_ddl;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_temp;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_type;
--empty folders
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_ddl/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_temp/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_utf8/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_type/*;

--- setup Hive tables
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_a.hive.sql;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_utf8.data /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_type.data /user/hive/exttables/tbl_type;

-- cleanup any left-over Trafodion objects
drop external table hivepi for hive.hive.hivepi;

log LOG005 clear;

set schema hive.hive;
set terminal_charset utf8;

cqd AUTO_QUERY_RETRY 'OFF';
cqd HIVE_MAX_STRING_LENGTH '32' ;
cqd CALL_EMBEDDED_ARKCMP 'OFF';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
------------------------------------------------------------
-- Testing query plan invalidation in the compiler, but
-- not the executor. Perform DML/DDL operations on a
-- table and try re-executing the old plan as well as
-- getting a query cache hit and updating the changed
-- Hive and HDFS metadata
------------------------------------------------------------

prepare s1 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;
execute s1;
-- expect 0 rows

prepare s1part from 
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s1part;
-- expect 0 rows

insert into hive.hive.hivenonp
values -- partition 1,one
       (1,1,1,'one'),
       (11,11,1,'one'),
       -- partition 2,two
       (2,2,2,'two'),
       (22,22,2,'two'),
       (222,222,2,'two'),
       -- partition 3,three
       (3,3,3,'three'),
       -- partition 3 or partition 3,four
       (34,34,3,'four');
select * from hive.hive.hivenonp;

-- insert some data and add one more partition
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_b.hive.sql;

-- query cache hit, no validation at all
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

-- vary query to avoid query cache hit
prepare s2 from 
  select c_preferred_cust_flag,
         count(c_customer_sk) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

prepare s2part from
  select c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  group by 1 
  order by 1
  ;
execute s1;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2;
-- should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

execute s1part;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2part;
-- although this should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

insert into customer_temp 
select * from customer 
where c_customer_sk between 20000 and 39999;

select * from newtable;
-- no rows, but should know the new table
insert into newtable values ('abc');
cqd query_cache '0';
select * from newtable;
-- expect to see the row, but only because query cache is off
cqd query_cache reset;

insert into hiveregr5.newtable2 values ('xyz');
select * from hiveregr5.newtable2;

-- add a second partition to customer_bp
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_c.hive.sql;
-- add more files to customer_ddl
sh regrhadoop.ksh dfs -cp /user/hive/exttables/customer_temp/* /user/hive/exttables/customer_ddl;

-- no query cache hit, but NATable cache hit
prepare s3 from 
  select count(*) 
  from customer_ddl 
  ;

-- no query cache hit, but NATable cache hit
prepare s3part from
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(c_customer_id) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s1;
-- s1 should still return 0 rows - for now
execute s2;
execute s3;
execute s1part;
-- s1 should still return 0 rows - for now
execute s2part;
execute s3part;

select a,b from newtable;
-- should return 0 rows

insert into newtable values (1, 'def');
select a,b from newtable;

-- overwrite the table with auto-generated partitions
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_d.hive.sql;

cqd query_cache '0';
prepare s4 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;
prepare s4part from
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s2;
execute s4;
execute s2part;
execute s4part;
select count(*) from tbl_utf8;
select * from tbl_utf8 where id between 8 and 12;
select * from tbl_utf8 where chapter like '%三%';
select * from tbl_utf8 where chapter like '%海印_昧%';

insert into tbl_utf8_temp 
select * from tbl_utf8;

select count(*) from tbl_utf8_temp;
select * from tbl_utf8_temp where id between 8 and 12;
select * from tbl_utf8_temp where chapter like '%海印_昧%';

select count(*) from tbl_utf8p;
select * from tbl_utf8p where id between 8 and 12;
select * from tbl_utf8p where chapter like '%海印_昧%';

select * from tbl_type;
insert into tbl_type_temp select * from tbl_type;
select * from tbl_type_temp;

cqd traf_enable_orc_format 'ON';
select * from hivenonp;
select * from hivepi;
select * from hiveps;
select * from hivepis;
select * from hivepio;
select * from hivepiso;

prepare s from
select * 
from hive.hive.hivepis
where id=2 and p1=2 and p2 = 'two' and (id<100 or p2='three');
select count(*)
from table(explain(null,'S'))
where operator like '%SCAN%'
  and description like '%part_elim_compiled%';
select count(*)
from table(explain(null,'S'))
where operator like '%SCAN%'
  and description like '%part_elim_runtime%';

select *,
       block__offset__inside__file,
       input__range__number,
       row__number__in__range
       --, cast(substring(input__file__name,1,100) as char(100)) file_name
from hive.hive.hivepis;
select input__range__number, row__number__in__range, block__offset__inside__file
from hive.hive.hivenonp;
select input__range__number, row__number__in__range, block__offset__inside__file
from hive.hive.hivepi;

prepare s from select * from hive.hive.hivepio;
execute s;
select * from hive.hive.hivepiso;

-- partition elimination on ORC table
select * from hive.hive.hivepio where p1=2;
select * from hive.hive.hivepio where p1 in (1,3);

-- this pred can neither be pushed to ORC nor used as
-- a partition elimination predicate
--select * from hive.hive.hivepio where p1=1 or col2<10;

set catalog trafodion;
create external table hivepi for hive.hive.hivepi;
set schema hive.hive;
update statistics for table hive.hive.hivepi on every column;
update statistics for table hivepis on every column;
update statistics for table hivepiso on every column --, INPUT__FILE__NAME, ROW__NUMBER__IN__RANGE
;

select cast(substring(o.object_name, 1, 20) as
            char(20) character set iso88591) object_name,
       cast(substring(c.column_name, 1, 20) as
            char(20) character set iso88591) col_name
  from trafodion."_MD_".objects o 
  join trafodion."_MD_".columns c on o.object_uid = c.object_uid
  join trafodion."_HIVESTATS_".sb_histograms g on g.table_uid = o.object_uid 
                       and g.column_number = c.column_number
  where o.object_type = 'BT'
    and o.object_name in ('HIVEPI', 'HIVEPIS', 'HIVEPISO')
order by 1, 2;

drop external table hivepi for hive.hive.hivepi;

log;
