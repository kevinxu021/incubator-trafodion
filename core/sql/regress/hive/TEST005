-- -*- mode: sql; coding: utf-8 -*-
-- Tests for SQL on Hadoop PoC
-- Test simple cases of partitioned tables
-- Very basic test of data types and Unicode
-- Basic test of metadata invalidation
-- Added April 2013
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_ddl;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_temp;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_type;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_gbk;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_dos;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_dos_num;
--empty folders
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_ddl/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_temp/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_utf8/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_type/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_gbk/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_dos/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_dos_num/*;

--- setup Hive tables
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_a.hive.sql;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_utf8.data /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_type.data /user/hive/exttables/tbl_type;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_gbk.data /user/hive/exttables/tbl_gbk;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_dos.data /user/hive/exttables/tbl_dos;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_dos_numeric.data /user/hive/exttables/tbl_dos_num;

-- cleanup any left-over Trafodion objects
drop external table hivepi for hive.hive.hivepi;

log LOG005 clear;

set schema hive.hive;
set terminal_charset utf8;

cqd AUTO_QUERY_RETRY 'OFF';
cqd HIVE_MAX_STRING_LENGTH '32' ;
cqd CALL_EMBEDDED_ARKCMP 'OFF';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
------------------------------------------------------------
-- Testing query plan invalidation in the compiler, but
-- not the executor. Perform DML/DDL operations on a
-- table and try re-executing the old plan as well as
-- getting a query cache hit and updating the changed
-- Hive and HDFS metadata
------------------------------------------------------------

prepare s1 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_temp
  group by 1 
  order by 1
  ;
execute s1;
-- expect 0 rows

prepare s1part from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_p 
  group by 1 
  order by 1
  ;
execute s1part;
-- expect 0 rows

insert into hive.hive.hivenonp
values -- partition 1,one
       (1,1,1,'one', timestamp '2001-01-01 01:23:45.678901', date '2001-01-01'),
       (11,11,1,'one', timestamp '2001-01-01 01:23:45.678901', date '2001-01-01'),
       -- partition 2,two
       (2,2,2,'two', timestamp '2002-02-02 02:34:56.789012', date '2020-02-29'),
       (22,22,2,'two', timestamp '2002-02-02 00:00:00.000000', date '2020-02-29'),
       (222,222,2,'two', timestamp '2002-02-02 02:34:56.789012', date '2020-02-29'),
       -- partition 3,three
       (3,3,3,'three', timestamp '2003-03-03 03:45:57.890123', date '2003-03-31'),
       -- partition 3 or partition 3,four
       (34,34,3,'four', timestamp '2004-04-04 04:56:18', date '2004-04-04');
select * from hive.hive.hivenonp;

insert into hive.hive.hivepis select id, col2, p1, p2 from hive.hive.hivenonp;
insert into hive.hive.hivepts select id, col2, p1t, p2 from hive.hive.hivenonp;
insert into hive.hive.hivepi  select id, col2, p1 from hive.hive.hivepis;
insert overwrite table hive.hive.hivepi  select id, col2, p1 from hive.hive.hivepis;
-- error, insert overwrite table not allowed for partitioned tables

prepare display_rows_accessed from
select val4_txt, val4
from table(statistics(null,null))
where tdb_name like '%_SCAN %';

select * from hivepi;
select count(*) from hivepis;
select * from hivepts where p2 = 'two';
execute display_rows_accessed;
select * from hivepi join hivepis on hivepi.p1 = hivepis.p1;

-- insert some data and add one more partition
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_b.hive.sql;

-- customer_ddl table is about 3 MB, make a plan with >= 2 ESPs
cqd HIVE_MIN_BYTES_PER_ESP_PARTITION '1000000';
cqd hive_max_string_length '32000';

prepare partinsert from
insert into hive.hive.customer_p
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from hive.hive.customer_ddl <<+cardinality 2.5e4 >>
where c_customer_sk < 20000
      -- blank partition column values not yet supported
      and c_preferred_cust_flag <> ' ';

-- go back to the smaller string length
cqd HIVE_MAX_STRING_LENGTH '32' ;

-- verify that we are indeed seeing a parallel plan
select count(*)
from table(explain(null,'PARTINSERT'))
where operator = 'ESP_EXCHANGE';

execute partinsert;

insert into customer_temp 
select * from customer 
where c_customer_sk between 20000 and 39999;

-- query cache hit, no validation at all
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

-- vary query to avoid query cache hit
prepare s2 from 
  select c_preferred_cust_flag,
         count(c_customer_sk) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

prepare s2part from
  select c_preferred_cust_flag,
         count(c_customer_sk) -- avoid query cache
  from customer_p 
  group by 1 
  order by 1
  ;
execute s1;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2;
-- should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

execute s1part;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2part;
-- although this should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

select * from newtable;
-- no rows, but should know the new table
insert into newtable values ('abc');
cqd query_cache '0';
select * from newtable;
-- expect to see the row, but only because query cache is off
cqd query_cache reset;

insert into hiveregr5.newtable2 values ('xyz');
select * from hiveregr5.newtable2;

-- recreate newtable and drop hive schema hiveregr5
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_c.hive.sql;

-- add duplicate rows to customer_p
insert into customer_p
select 
    c_customer_sk,
    c_customer_id,
    c_current_cdemo_sk,
    c_current_hdemo_sk,
    c_current_addr_sk,
    c_first_shipto_date_sk,
    c_first_sales_date_sk,
    c_salutation,
    c_first_name,
    c_last_name,
    c_birth_day,
    c_birth_month,
    c_birth_year,
    c_birth_country,
    c_login,
    c_email_address,
    c_last_review_date,
    c_preferred_cust_flag
from customer_ddl
where c_customer_sk between 20000 and 24999
      -- blank partition column values not yet supported
      and c_preferred_cust_flag <> ' ';

-- no query cache hit, but NATable cache hit
prepare s3 from 
  select count(*) 
  from customer_ddl 
  ;

-- no query cache hit, but NATable cache hit
prepare s3part from
  select c_preferred_cust_flag,
         count(c_customer_id) 
  from customer_p 
  group by 1 
  order by 1
  ;
execute s1;
-- s1 should still return 0 rows - for now
execute s2;
execute s3;
execute s1part;
-- s1 should still return 0 rows - for now
execute s2part;
execute s3part;

select a,b from newtable;
-- should return 0 rows

insert into newtable values (1, 'def');
select a,b from newtable;

-- overwrite customer_p and tbl_utf8p with auto-generated partitions
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_d.hive.sql;

cqd query_cache '0';
prepare s4 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;
prepare s4part from
  select c_preferred_cust_flag,
         count(*) 
  from customer_p 
  group by 1 
  order by 1
  ;
execute s2;
execute s4;
execute s2part;
-- error 8442 since the files we are trying to open no longer exist
execute s4part;
select count(*) from tbl_utf8;
select * from tbl_utf8 where id between 8 and 12;
select * from tbl_utf8 where chapter like '%三%';
select * from tbl_utf8 where chapter like '%海印_昧%';

insert into tbl_utf8_temp 
select * from tbl_utf8;

select count(*) from tbl_utf8_temp;
select * from tbl_utf8_temp where id between 8 and 12;
select * from tbl_utf8_temp where chapter like '%海印_昧%';

select count(*) from tbl_utf8p;
select * from tbl_utf8p where id between 8 and 12;
select * from tbl_utf8p where chapter like '%海印_昧%';

select * from tbl_type;
insert into tbl_type_temp select * from tbl_type;
select * from tbl_type_temp;

cqd traf_enable_orc_format 'ON';
select * from hivenonp;
select * from hivepi;
select * from hiveps;
select * from hivepis;
select * from hivepts;
select * from hivepio;
select * from hivepdo;
select * from hivepiso;

prepare s from
select * 
from hive.hive.hivepis
where id=2 and p1=2 and p2 = 'two' and p2 > ? and (id<100 or p2='three');
--             compile  compile        runtime     not a part elim pred
select count(*)
from table(explain(null,'S'))
where operator like '%SCAN%'
  and description like '%part_elim_compiled%';
select count(*)
from table(explain(null,'S'))
where operator like '%SCAN%'
  and description like '%part_elim_runtime%';
select * from hive.hive.hivepts where p1t > timestamp '2002-01-01 00:00:00.000000' and p2 <> 'four';
execute display_rows_accessed;
select * from hive.hive.hivepts where p1t < current_timestamp;
execute display_rows_accessed;

select *,
       block__offset__inside__file,
       input__range__number,
       row__number__in__range
       --, cast(substring(input__file__name,1,100) as char(100)) file_name
from hive.hive.hivepis;
select input__range__number, row__number__in__range, block__offset__inside__file
from hive.hive.hivenonp;
select input__range__number, row__number__in__range, block__offset__inside__file
from hive.hive.hivepi;

prepare s from select * from hive.hive.hivepio;
execute s;
select * from hive.hive.hivepiso;

-- partition elimination on ORC table
select * from hive.hive.hivepio where p1=2;
execute display_rows_accessed;
select * from hive.hive.hivepio where p1 in (1,3);
execute display_rows_accessed;
select * from hive.hive.hivepdo where p1d >= date '2002-12-31';
execute display_rows_accessed;

-- this pred can neither be pushed to ORC nor used as
-- a partition elimination predicate
select * from hive.hive.hivepio where p1=1 or col2<10;

set catalog trafodion;
create external table hivepi for hive.hive.hivepi;
set schema hive.hive;
update statistics for table hive.hive.hivepi on every column;
update statistics for table hivepis on every column;
update statistics for table hivepiso on every column;

select cast(substring(o.object_name, 1, 20) as
            char(20) character set iso88591) object_name,
       cast(substring(c.column_name, 1, 20) as
            char(20) character set iso88591) col_name
  from trafodion."_MD_".objects o 
  join trafodion."_MD_".columns c on o.object_uid = c.object_uid
  join trafodion."_HIVESTATS_".sb_histograms g on g.table_uid = o.object_uid 
                       and g.column_number = c.column_number
  where o.object_type = 'BT'
    and o.object_name in ('HIVEPI', 'HIVEPIS', 'HIVEPISO')
order by 1, 2;

drop external table hivepi for hive.hive.hivepi;

cqd HIVE_FILE_CHARSET 'GBK';
select c1, CONVERTTOHEX(c2) from tbl_gbk;
cqd HIVE_FILE_CHARSET reset;

cqd HIVE_SCAN_SPECIAL_MODE '1';
select * from tbl_dos;
cqd HIVE_SCAN_SPECIAL_MODE reset;
drop table if exists trafodion.seabase.tbl_dos_num;
create table trafodion.seabase.tbl_dos_num (c1 int, c2 int);
load with NO OUTPUT into trafodion.seabase.tbl_dos_num select * from tbl_dos_num;
cqd HIVE_SCAN_SPECIAL_MODE '1';
load with no output into trafodion.seabase.tbl_dos_num select * from tbl_dos_num;
select * from trafodion.seabase.tbl_dos_num;
cqd HIVE_SCAN_SPECIAL_MODE reset;
log;
